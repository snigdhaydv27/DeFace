## Getting Started

First, run the development server:

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.


# DeFace - AI vs Deepfake vs Real Image Classifier ğŸ§ ğŸ­

DeFace is a powerful web-based platform that classifies images into **Real**, **AI-generated**, or **Deepfake** using Googleâ€™s ViT (Vision Transformer) architecture. Built with a focus on **cybersecurity**, this tool aids in verifying image authenticity to combat digital misinformation and manipulated media.

---

## ğŸš€ Problem Statement

**Detect and classify images as Real, AI-generated, or Deepfake.**  
This project aims to provide a robust solution to image authenticity challenges in the era of AI-generated content.

---

## ğŸ›  Tech Stack

- **Frontend**: Next.js (React Framework), Tailwind CSS  
- **Backend**: Node.js + Express.js  
- **Authentication**: JWT (JSON Web Tokens)  
- **Database**: MongoDB Atlas  
- **ML Model**: Googleâ€™s ViT (Vision Transformer)  
- **Deployment**: Vercel

---

## ğŸ” Key Features

- **Triple Classification**: Distinguishes between Real, AI, and Deepfake images.
- **High Accuracy**: Achieves **97.5% accuracy** on benchmark datasets like FaceForensics++ and CelebDF.
- **Hybrid ML Model**: Combines CNNs and ViT to capture both local and global features.
- **Explainable Output**: Classification scores visualized via bar charts.
- **Secure Uploads**: Multer handles image uploads with security.

---

## ğŸ“¦ Use Cases

- ğŸ•µï¸â€â™‚ï¸ **Image Verification**  
- ğŸ§‘â€âš–ï¸ **Forensic Analysis**  
- ğŸ“± **Content Moderation**  
- ğŸ“° **Media & Journalism Validation**  
- ğŸ­ **Deepfake Detection in Celeb Content**  
- ğŸ’¬ **Dating & Social App Profile Filtering**  
- ğŸ•µï¸ **Law Enforcement Support**  
- ğŸ› **NGO & Government Anti-Misinformation Tool**

---

## ğŸ“ˆ Business Potential

- **Market Value**: The deepfake detection market is projected to reach **$10.7B by 2030** with a **41.6% CAGR**.
- **Compliance Ready**: Meets upcoming regulations like the **EU AI Act** and Indian **IT Act**.
- **Generalization Scope**: Adapts well to known deepfake methods, with future-proofing for emerging techniques.

---

## âš ï¸ Limitations

- Biased or limited datasets may reduce performance.
- May underperform on extremely low or high-resolution images.
- ViTâ€™s decision process is less interpretableâ€”but visual scores help clarify results.

---

## ğŸ‘¨â€ğŸ’» Team AI-liens

- **Aryan Kumar Arya** (Team Leader) - Dual Degree, CSE, Year II  
- **Snigdha Kumar** - Dual Degree, CSE, Year II  
- **Navneet Shreya** - B.Tech, CSE, Year II  
**Institute**: National Institute of Technology, Patna

---

## ğŸ“š References

- [AI-vs-Deepfake-vs-Real Model on HuggingFace](https://huggingface.co/prithivMLmods/AI-vs-Deepfake-vs-Real)  
- [A Sanity Check for AI-generated Image Detection â€“ arXiv](https://arxiv.org/abs/2406.19435)

---

## ğŸ“ Deployment

ğŸ”—[Vercel](https://deface-sand.vercel.app/)

---

## ğŸ“¸ Screenshots

### ğŸ“¤ Flowchart of Project
![Upload Page](/frontend/public/diagram.png)

### ğŸ–¼ï¸ Home Page
![Home Page](/frontend/public/home.png)

### ğŸ“Š Classification Output
![Classification Output](/frontend/public/classify.png)
![Classification Output](/frontend/public/classify2.png)

---

## ğŸ›¡ï¸ License

This project is licensed under MIT License. See `LICENSE` for more details.


